{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Key PyTorch Components\n",
        "## torch.nn\n",
        "Contains all the building blocks for neural networks in PyTorch, such as layers, activation functions, and loss functions. It allows you to construct computational graphs, which are sequences of computations executed in a specific order.\n",
        "\n",
        "## torch.nn.Parameter\n",
        "A subclass of torch.Tensor that is automatically registered as a parameter when assigned as an attribute to an nn.Module. Parameters are tensors that are considered model parameters, and if requires_grad=True (the default), gradients are automatically computed for them during backpropagation.\n",
        "\n",
        "## torch.nn.Module\n",
        "The base class for all neural network modules in PyTorch. It provides a way to encapsulate parameters, helpers for moving them to GPUs, exporting, loading, and more. All custom models should subclass nn.Module and implement the forward() method.\n",
        "\n",
        "## torch.optim\n",
        "Contains optimization algorithms (optimizers) used to update the parameters of a model based on the gradients computed during backpropagation. Optimizers adjust the weights to minimize the loss function.\n",
        "\n",
        "## def forward()\n",
        "All subclasses of nn.Module must implement the forward() method, which defines how the model processes input data and produces output. This is where the actual computation happens."
      ],
      "metadata": {
        "id": "xZnClKqznUlD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensors\n",
        "\n",
        "Tensors are multi-dimensional arrays that store data.\n",
        "\n",
        "hey generalize scalars, vectors, and matrices to higher dimensions and are the foundation of machine learning frameworks like PyTorch and TensorFlow.\n",
        "\n",
        "Scalar (0D tensor): A single number, e.g., 5.\n",
        "\n",
        "Vector (1D tensor): A list of numbers, e.g., [1, 2, 3].\n",
        "\n",
        "Matrix (2D tensor): A table of numbers, [[1, 2],\n",
        " [3, 4]]\n",
        "\n",
        " Higher-dimensional tensors (3D, 4D, etc.): Extend matrices to more dimensions, e.g., a batch of images (4D)."
      ],
      "metadata": {
        "id": "868P3Ex0KlKA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combining tensors is necessary for batch processing, organization, and efficient computation."
      ],
      "metadata": {
        "id": "u3kLXOHCL7R8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#View - Is used to flatten the matrix\n",
        "\n",
        "memory is contigeous memory"
      ],
      "metadata": {
        "id": "f9vjiYp9hnjX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfwmjtDfhkXR",
        "outputId": "d94ea70c-0b57-4cc0-cd32-3135cbde70ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4456, 0.8219, 0.2376, 0.3831],\n",
            "        [0.8598, 0.6074, 0.0059, 0.1892],\n",
            "        [0.8744, 0.6607, 0.1270, 0.2809],\n",
            "        [0.9162, 0.5762, 0.1097, 0.4148]])\n",
            "tensor([0.4456, 0.8219, 0.2376, 0.3831, 0.8598, 0.6074, 0.0059, 0.1892, 0.8744,\n",
            "        0.6607, 0.1270, 0.2809, 0.9162, 0.5762, 0.1097, 0.4148])\n",
            "tensor([[0.4456, 0.8219, 0.2376, 0.3831, 0.8598, 0.6074, 0.0059, 0.1892],\n",
            "        [0.8744, 0.6607, 0.1270, 0.2809, 0.9162, 0.5762, 0.1097, 0.4148]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "tensor_random=torch.rand(4,4)\n",
        "print(tensor_random)\n",
        "\n",
        "print(tensor_random.view(16))\n",
        "print(tensor_random.view(2,8))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reshape\n",
        "\n",
        "more flexible\n",
        "\n",
        "It uses contigeous memory as well + non contiguous memory\n",
        "\n",
        "contiguous memory then use view.\n"
      ],
      "metadata": {
        "id": "ZYMUs8Bnj7-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reshape\n",
        "tensor_random=torch.rand(4,4)\n",
        "print(tensor_random)\n",
        "\n",
        "print(tensor_random.reshape(16))\n",
        "print(tensor_random.reshape(2,8))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyLn7MAnh1fx",
        "outputId": "a9295525-fdee-4ef4-c3aa-c5be191f2762"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9698, 0.3375, 0.9843, 0.4118],\n",
            "        [0.5258, 0.3957, 0.1894, 0.1267],\n",
            "        [0.2521, 0.8703, 0.6007, 0.9123],\n",
            "        [0.1984, 0.6291, 0.9960, 0.1445]])\n",
            "tensor([0.9698, 0.3375, 0.9843, 0.4118, 0.5258, 0.3957, 0.1894, 0.1267, 0.2521,\n",
            "        0.8703, 0.6007, 0.9123, 0.1984, 0.6291, 0.9960, 0.1445])\n",
            "tensor([[0.9698, 0.3375, 0.9843, 0.4118, 0.5258, 0.3957, 0.1894, 0.1267],\n",
            "        [0.2521, 0.8703, 0.6007, 0.9123, 0.1984, 0.6291, 0.9960, 0.1445]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Stack\n",
        "\n",
        "Stacking is generally used in situations where you need to combine tensors while introducing a new dimension."
      ],
      "metadata": {
        "id": "I1b-dzPamPab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_stack=torch.stack([tensor_random,tensor_random,tensor_random,tensor_random])\n",
        "print(random_stack)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JSHyxj6kAdC",
        "outputId": "3abc24a2-8b80-4a16-de42-38085f895d6e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.9698, 0.3375, 0.9843, 0.4118],\n",
            "         [0.5258, 0.3957, 0.1894, 0.1267],\n",
            "         [0.2521, 0.8703, 0.6007, 0.9123],\n",
            "         [0.1984, 0.6291, 0.9960, 0.1445]],\n",
            "\n",
            "        [[0.9698, 0.3375, 0.9843, 0.4118],\n",
            "         [0.5258, 0.3957, 0.1894, 0.1267],\n",
            "         [0.2521, 0.8703, 0.6007, 0.9123],\n",
            "         [0.1984, 0.6291, 0.9960, 0.1445]],\n",
            "\n",
            "        [[0.9698, 0.3375, 0.9843, 0.4118],\n",
            "         [0.5258, 0.3957, 0.1894, 0.1267],\n",
            "         [0.2521, 0.8703, 0.6007, 0.9123],\n",
            "         [0.1984, 0.6291, 0.9960, 0.1445]],\n",
            "\n",
            "        [[0.9698, 0.3375, 0.9843, 0.4118],\n",
            "         [0.5258, 0.3957, 0.1894, 0.1267],\n",
            "         [0.2521, 0.8703, 0.6007, 0.9123],\n",
            "         [0.1984, 0.6291, 0.9960, 0.1445]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_stack = torch.randn(2, 3)\n",
        "print(random_stack)\n",
        "print(random_stack.shape)\n",
        "\n",
        "\n",
        "random_stack = torch.tensor([[ 0.5174, -1.6801, -1.7602],\n",
        "                             [ 1.2056, -0.1794,  0.9064]])\n",
        "random_stack"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9hbDFoumYIx",
        "outputId": "9a8d65ab-2979-4378-fe93-1506988cf675"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.8234,  0.8921, -0.5843],\n",
            "        [-0.6360, -0.3497, -0.8274]])\n",
            "torch.Size([2, 3])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.5174, -1.6801, -1.7602],\n",
              "        [ 1.2056, -0.1794,  0.9064]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# By Default dimension is 0\n",
        "print(\"Dimension 0 or default\")\n",
        "random_stack_dim_default = torch.stack((random_stack, random_stack))\n",
        "print(random_stack_dim_default)\n",
        "print(random_stack_dim_default.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdMWHa4YH_5O",
        "outputId": "c545d0be-72f1-47bc-877b-29b6531e0149"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimension 0 or default\n",
            "tensor([[[ 0.5174, -1.6801, -1.7602],\n",
            "         [ 1.2056, -0.1794,  0.9064]],\n",
            "\n",
            "        [[ 0.5174, -1.6801, -1.7602],\n",
            "         [ 1.2056, -0.1794,  0.9064]]])\n",
            "torch.Size([2, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch Intermediate"
      ],
      "metadata": {
        "id": "_sIZqpxuOCIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "6WkRZbhmIkqF"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input data\n",
        "X= torch.tensor([[1.0],[4.0],[7.0]])\n",
        "\n",
        "# Output data (Target)\n",
        "Y= torch.tensor([[2.0],[8.0],[11.0]])"
      ],
      "metadata": {
        "id": "iV8C0RegQEOc"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Defining the class name of the nn.module\n",
        "\n",
        "name of class - Linearregression Model (which inherits the nn.module)\n",
        "\n",
        "init is the constructor which has layers and parameters of the module\n",
        "\n",
        "super of init = this initailises the base class nn.module()\n",
        "\n",
        "self.Linear = contains nn.layer(Linear layer that applies a linear transformation) y=w.x+b which has x and y features\n",
        "in_features = 1, out_features = total no of output we want.\n",
        "\n",
        "Forward= Forward propagation, where computation happens\n",
        "\n",
        "out= self.linear(x) = applies the linear transformation to the input.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Kn1YEZxFeB-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegressionModel(nn.Module): # inherenting the object\n",
        "  def __init__(self):\n",
        "    super(LinearRegressionModel, self).__init__()\n",
        "    # Define model's parameter\n",
        "    self.linear= nn.Linear(in_features=1, out_features=1)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.relu(self.linear(x))\n"
      ],
      "metadata": {
        "id": "YPpY3k0zP-qe"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LinearRegressionModel()"
      ],
      "metadata": {
        "id": "nbCx_3kKdyJe"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss Function\n",
        "\n",
        "The loss function guides the optimization process by providing feedback to the model about its performance, enabling it to adjust parameters (via backpropagation) and improve predictions."
      ],
      "metadata": {
        "id": "GyDQpJ8Zgc6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss function\n",
        "\n",
        "criterion= nn.MSELoss()\n",
        "\n",
        "#Optimizer - tool to find the lowest valley such as gradient descent\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n"
      ],
      "metadata": {
        "id": "v5C1-Y1adx4p"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epoch = 10\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "  y_pred = model(X)\n",
        "\n",
        "  # Compute loss\n",
        "  loss = criterion(y_pred, Y)\n",
        "\n",
        "  optimizer.zero_grad() # Clearing the old gradients\n",
        "\n",
        "  loss.backward()  # Backward pass : compute gradients\n",
        "\n",
        "  optimizer.step() # Update the parameters\n",
        "\n",
        "  print(f\"Epoch {epoch+1}/{num_epoch}, loss:{loss.item() : .4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3t9UAqUdxjj",
        "outputId": "dbffddba-4cdd-426f-ad1d-e7b55b705d53"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, loss: 19.6374\n",
            "Epoch 2/10, loss: 6.1917\n",
            "Epoch 3/10, loss: 2.1939\n",
            "Epoch 4/10, loss: 1.0053\n",
            "Epoch 5/10, loss: 0.6518\n",
            "Epoch 6/10, loss: 0.5467\n",
            "Epoch 7/10, loss: 0.5155\n",
            "Epoch 8/10, loss: 0.5061\n",
            "Epoch 9/10, loss: 0.5034\n",
            "Epoch 10/10, loss: 0.5025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Model weights {model.linear.weight.data}\")\n",
        "print(f\"Model bias {model.linear.bias.data}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlNEFtI1iOp2",
        "outputId": "f116e162-2d0c-4cfc-d055-cae457b36181"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model weights tensor([[1.5142]])\n",
            "Model bias tensor([0.9111])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test the model"
      ],
      "metadata": {
        "id": "wifvLvwejewp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####torch.no_grad()\n",
        "During inference or evaluation, we don’t need gradients since we’re not training the model or updating weights. This saves memory and speeds up computation."
      ],
      "metadata": {
        "id": "wlsR-GTzlzwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():    # we are not updating the gradient, we are predicting the gradients\n",
        "  predicted = model(X)\n",
        "  print(\"Inupt vale: \", X[:, 0])\n",
        "  print(\"Input value: \", X.squeeze()) # numpy or squeeze we can use\n",
        "  print(\"Input value: \", X[:,0].numpy())\n",
        "  print(\"==\"*20)\n",
        "  print(\"Predicted value: \", predicted.squeeze().numpy())\n",
        "  print(\"Actual value: \", Y.squeeze().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y135gsEVivUG",
        "outputId": "19d42077-0b17-4a4f-cdb9-0de73f16f16c"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inupt vale:  tensor([1., 4., 7.])\n",
            "Input value:  tensor([1., 4., 7.])\n",
            "Input value:  [1. 4. 7.]\n",
            "========================================\n",
            "Predicted value:  [ 2.4252748  6.9678636 11.510452 ]\n",
            "Actual value:  [ 2.  8. 11.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Training Loop: Iterates over the dataset multiple times (epochs) to train the model.\n",
        "* y_pred = model(X): Performs the forward pass by calling the model on the input data. This invokes the forward() method.\n",
        "* loss = criterion(y_pred, y): Computes the loss between the predicted values and actual values.\n",
        "* optimizer.zero_grad(): Clears old gradients before computing new ones.\n",
        "* loss.backward(): Performs backpropagation to compute gradients of the loss w.r.t. model parameters.\n",
        "* optimizer.step(): Updates the model parameters using the computed gradients.\n",
        "* Progress Printing: Every 2 epochs, prints the current loss to monitor training progress."
      ],
      "metadata": {
        "id": "Hi4Xb2Tym1uL"
      }
    }
  ]
}